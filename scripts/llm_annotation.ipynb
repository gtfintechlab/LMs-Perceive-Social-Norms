{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29d438ee-52cf-4ebe-b1f9-37a1b5b54bab",
   "metadata": {},
   "source": [
    "# LLM Annotation\n",
    "\n",
    "Code to inference all the LLMs in the study. Note that the code requires API keys to inference LMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e2ab6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep, time\n",
    "from datetime import date\n",
    "import threading\n",
    "from typing import Tuple\n",
    "\n",
    "# pip install openai\n",
    "from openai import OpenAI\n",
    "import google.generativeai as genai\n",
    "from google.ai import generativelanguage as glm\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "# If you don't want to use environmental variables you can add your api key directly to api_key\n",
    "togetherai_api_key = os.environ.get('TOGETHERAI_API_KEY')\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "google_api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "\n",
    "# together.ai key\n",
    "client_together = OpenAI(api_key=togetherai_api_key,\n",
    "                base_url='https://api.together.xyz')\n",
    "\n",
    "#  OpenAI key\n",
    "client_openai = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Gemini key (https://ai.google.dev/gemini-api/docs/quickstart?lang=python)\n",
    "genai.configure(api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12bb67c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get date\n",
    "today = date.today()\n",
    "\n",
    "# load subset of data with 50 annotations per RoT\n",
    "df_data = pd.read_csv('../data/human_data/social_chem_101_m50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cc4950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_prompt_generator(row: pd.Series,\n",
    "                         prompt_name: str,\n",
    "                         rot: bool = False,\n",
    "                         action: bool = False,\n",
    "                         demographic: bool = False) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Generates prompt string and annotation table for llm based on rot, action, and demographic.\n",
    "\n",
    "    Parameters:\n",
    "    row (pd.Series): A pandas Series containing columns needed to form every prompt string for llm (e.g., 'rot', 'action')\n",
    "    prompt_name (str): Name of column with associated worker label information  (e.g., 'rot-agree', 'action-agency').\n",
    "    rot (bool): Whether to generate prompts that incorporate 'action' from social chemistry dataset. There are thousands of actions in dataset and only 400 rot.\n",
    "    action (bool): (**NOT IMPLEMENTED PROPERLY YET** and will lead to an error) Whether to generate prompts that incorporate 'action' from social chemistry dataset. There are thousands of actions in dataset and only 400 rot.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A formatted prompt (element 0) AND a formatted prompt + annotable table (element 1) that can be used to feed into a LLM to be annotated. \n",
    "           Currently element 1 is the summation of formatted prompt + annotable table.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt_name_llm = prompt_name + '-llm-prompt' \n",
    "\n",
    "    prompt_switch = {}\n",
    "    \n",
    "    if demographic:\n",
    "        df_data['income_dollars'] = (df_data['income'] * 1000).apply(lambda x: f\"{x:,} dollars\")\n",
    "    else: \n",
    "        df_data['income_dollars'] = ''\n",
    "    \n",
    "    if rot: \n",
    "        rot = row['rot']    \n",
    "\n",
    "        #A rule of thumb is a descriptive cultural norm structured as the judgment of an action. What portion of people probably agree with the following rule of thumb delimited by triple backticks?\n",
    "        rot_prompts = {'rot-agree-llm-prompt': (\"A rule of thumb is a descriptive cultural norm structured as the judgment of an action. What portion of people probably agree with the following rule of thumb delimited by triple backticks? Provide the answer in the first line.\\n\"\n",
    "                                       f\"rule of thumb: ```{rot}```\\n\"\n",
    "                                       f\"Options:\\n\"\n",
    "                                       f\"A) <1%\\n\"\n",
    "                                       f\"B) 5%-25%\\n\"\n",
    "                                       f\"C) 50%\\n\"\n",
    "                                       f\"D) 75%-90%\\n\"\n",
    "                                       f\"E) >90%\\n\"\n",
    "        , \"A rule of thumb is a descriptive cultural norm structured as the judgment of an action. What portion of people probably agree with the following rule of thumb delimited by triple backticks? Provide the answer in the first line.\\n\"\n",
    "                                       f\"rule of thumb: ```{rot}```\\n\"\n",
    "                                       f\"Options:\\n\"\n",
    "                                       f\"A): <1% Almost no one agrees with this.\\n\"\n",
    "                                       f\"B): 5%-25% A small portion of people occasionally agree with this.\\n\"\n",
    "                                       f\"C): 50% This is a controversial belief; people are likely to be divided.\\n\"\n",
    "                                       f\"D): 75%-90% This is a common belief, shared by many.\\n\"\n",
    "                                       f\"E): >90% This is a universally accepted belief.\\n\"       \n",
    ",\n",
    "f\"\\nRefer to the markdown table delimited by triple backticks below for a description of each option.\\n\"\n",
    "f\"\"\"```\n",
    "| Option  | Description                               |\n",
    "|---------|-------------------------------------------|\n",
    "| <1%     | Almost no one thinks this                 |\n",
    "| 5%-25%  | People occasionally think this            |\n",
    "| 50%     | Controversial (people naturally disagree) |\n",
    "| 75%-90% | Common belief                             |\n",
    "| >90%    | Universally true                          |\n",
    "```\n",
    "\"\"\"\n",
    ",\n",
    "f\"\\nRefer to the markdown table delimited by triple backticks below for an example of each option.\\n\"\n",
    "                                       f\"\"\"```\n",
    "| Option  | Description                               | Example                                       |\n",
    "|---------|-------------------------------------------|-----------------------------------------------|\n",
    "| <1%     | Almost no one thinks this                 | Murdering people is great.                    |\n",
    "| 5%-25%  | People occasionally think this            | It's okay to not feel guilty when you cheat.  |\n",
    "| 50%     | Controversial (people naturally disagree) | It's good to be on a diet.                    |\n",
    "| 75%-90% | Common belief                             | You shouldn't keep secrets from your partner. |\n",
    "| >90%    | Universally true                          | It\\'s bad to kill people.                     |\n",
    "```\n",
    "\"\"\"\n",
    ",\n",
    "\"Discard all previous instructions. A rule of thumb is a descriptive cultural norm structured as the judgment of an action. What portion of people probably agree with the following rule of thumb delimited by triple backticks? Provide the answer in the first line.\\n\"\n",
    "\n",
    "f\"\\nExample 1:\\n\"\n",
    "f\"Rule of thumb: ```Murdering people is great.```\\n\"\n",
    "f\"Options:\\n\"\n",
    "f\"A) <1%\\n\"\n",
    "f\"B) 5%-25%\\n\"\n",
    "f\"C) 50%\\n\"\n",
    "f\"D) 75%-90%\\n\"\n",
    "f\"E) >90%\\n\"\n",
    "\n",
    "f\"\\nAnswer: A\\n\"\n",
    "f\"Description: Almost no one thinks this\\n\"\n",
    "\n",
    "f\"\\nExample 2:\\n\"\n",
    "f\"Rule of thumb: ```It's okay to not feel guilty when you cheat.```\\n\"\n",
    "f\"Options:\\n\"\n",
    "f\"A) <1%\\n\"\n",
    "f\"B) 5%-25%\\n\"\n",
    "f\"C) 50%\\n\"\n",
    "f\"D) 75%-90%\\n\"\n",
    "f\"E) >90%\\n\"\n",
    "\n",
    "f\"\\nAnswer: B\\n\"\n",
    "f\"Description: People occasionally think this\\n\"\n",
    "\n",
    "f\"\\nExample 3:\\n\"\n",
    "f\"Rule of thumb: ```It's good to be on a diet.```\\n\"\n",
    "f\"Options:\\n\"\n",
    "f\"A) <1%\\n\"\n",
    "f\"B) 5%-25%\\n\"\n",
    "f\"C) 50%\\n\"\n",
    "f\"D) 75%-90%\\n\"\n",
    "f\"E) >90%\\n\"\n",
    "\n",
    "f\"\\nAnswer: C\\n\"\n",
    "f\"Description: Controversial (people naturally disagree)\\n\"\n",
    "\n",
    "f\"\\nExample 4:\\n\"\n",
    "f\"Rule of thumb: ```You shouldn't keep secrets from your partner.```\\n\"\n",
    "f\"Options:\\n\"\n",
    "f\"A) <1%\\n\"\n",
    "f\"B) 5%-25%\\n\"\n",
    "f\"C) 50%\\n\"\n",
    "f\"D) 75%-90%\\n\"\n",
    "f\"E) >90%\\n\"\n",
    "\n",
    "f\"\\nAnswer: D\\n\"\n",
    "f\"Description: Common belief\\n\"\n",
    "\n",
    "f\"\\nExample 5:\\n\"\n",
    "f\"Rule of thumb: ```It's bad to kill people.```\\n\"\n",
    "f\"Options:\\n\"\n",
    "f\"A) <1%\\n\"\n",
    "f\"B) 5%-25%\\n\"\n",
    "f\"C) 50%\\n\"\n",
    "f\"D) 75%-90%\\n\"\n",
    "f\"E) >90%\\n\"\n",
    "\n",
    "f\"\\nAnswer: E\\n\"\n",
    "f\"Description: Universally true\\n\"\n",
    "\n",
    "f\"\\nNow, it's your turn to answer the following question:\\n\"\n",
    "\n",
    "f\"Rule of thumb: ``{rot}```\\n\"\n",
    "f\"Options:\\n\"\n",
    "f\"A) <1%\\n\"\n",
    "f\"B) 5%-25%\\n\"\n",
    "f\"C) 50%\\n\"\n",
    "f\"D) 75%-90%\\n\"\n",
    "f\"E) >90%\\n\"\n",
    ",\n",
    "\"Discard all previous instructions. A rule of thumb is a descriptive cultural norm structured as the judgment of an action. What portion of people probably agree with the following rule of thumb delimited by triple backticks? Provide the answer in the first line.\\n\"\n",
    "\n",
    "f\"\\nExample 1:\\n\"\n",
    "f\"Rule of thumb: ```Murdering people is great.```\\n\"\n",
    "f\"Options:\\n\"\n",
    "f\"A): <1% Almost no one agrees with this.\"\n",
    "f\"B): 5%-25% A small portion of people occasionally agree with this.\"\n",
    "f\"C): 50% This is a controversial belief; people are likely to be divided.\"\n",
    "f\"D): 75%-90% This is a common belief, shared by many.\"\n",
    "f\"E): >90% This is a universally accepted belief.\"\n",
    "\n",
    "f\"\\nAnswer: A\\n\"\n",
    "\n",
    "f\"\\nExample 2:\\n\"\n",
    "f\"Rule of thumb: ```It's okay to not feel guilty when you cheat.```\\n\"\n",
    "f\"Options:\\n\"\n",
    "f\"A): <1% Almost no one agrees with this.\"\n",
    "f\"B): 5%-25% A small portion of people occasionally agree with this.\"\n",
    "f\"C): 50% This is a controversial belief; people are likely to be divided.\"\n",
    "f\"D): 75%-90% This is a common belief, shared by many.\"\n",
    "f\"E): >90% This is a universally accepted belief.\"\n",
    "\n",
    "f\"\\nAnswer: B\\n\"\n",
    "\n",
    "f\"\\nExample 3:\\n\"\n",
    "f\"Rule of thumb: ```It's good to be on a diet.```\\n\"\n",
    "f\"Options:\\n\"\n",
    "f\"A): <1% Almost no one agrees with this.\"\n",
    "f\"B): 5%-25% A small portion of people occasionally agree with this.\"\n",
    "f\"C): 50% This is a controversial belief; people are likely to be divided.\"\n",
    "f\"D): 75%-90% This is a common belief, shared by many.\"\n",
    "f\"E): >90% This is a universally accepted belief.\"\n",
    "\n",
    "f\"\\nAnswer: C\\n\"\n",
    "\n",
    "f\"\\nExample 4:\\n\"\n",
    "f\"Rule of thumb: ```You shouldn't keep secrets from your partner.```\\n\"\n",
    "f\"Options:\\n\"\n",
    "f\"A): <1% Almost no one agrees with this.\"\n",
    "f\"B): 5%-25% A small portion of people occasionally agree with this.\"\n",
    "f\"C): 50% This is a controversial belief; people are likely to be divided.\"\n",
    "f\"D): 75%-90% This is a common belief, shared by many.\"\n",
    "f\"E): >90% This is a universally accepted belief.\"\n",
    "\n",
    "f\"\\nAnswer: D\\n\"\n",
    "\n",
    "f\"\\nExample 5:\\n\"\n",
    "f\"Rule of thumb: ```It's bad to kill people.```\\n\"\n",
    "f\"Options:\\n\"\n",
    "f\"A): <1% Almost no one agrees with this.\"\n",
    "f\"B): 5%-25% A small portion of people occasionally agree with this.\"\n",
    "f\"C): 50% This is a controversial belief; people are likely to be divided.\"\n",
    "f\"D): 75%-90% This is a common belief, shared by many.\"\n",
    "f\"E): >90% This is a universally accepted belief.\"\n",
    "\n",
    "f\"\\nAnswer: E\\n\"\n",
    "\n",
    "f\"\\nNow, it's your turn to answer the following question:\\n\"\n",
    "\n",
    "f\"Rule of thumb: ``{rot}```\\n\"\n",
    "f\"Options:\\n\"\n",
    "f\"A): <1% Almost no one agrees with this.\"\n",
    "f\"B): 5%-25% A small portion of people occasionally agree with this.\"\n",
    "f\"C): 50% This is a controversial belief; people are likely to be divided.\"\n",
    "f\"D): 75%-90% This is a common belief, shared by many.\"\n",
    "f\"E): >90% This is a universally accepted belief.\"\n",
    "                                       ),\n",
    "\n",
    "                         # rot-categorization (multiple selections possible) has some nans (105) so it will have to be dealt with \n",
    "                         'rot-categorization-llm-prompt': (\"What category best fits the rule of thumb?\\n\"\n",
    "                                       f\"rule of thumb: {rot}\\n\"\n",
    "                                       f\"Options:\\n\"\n",
    "                                       f\"A) Morality/Ethics\\n\"\n",
    "                                       f\"B) Social Norms\\n\"\n",
    "                                       f\"C) Advice\\n\"\n",
    "                                       f\"D) It is what it is\\n\"\n",
    "                                       \"You are allowed to select from none through all options, but you are encouraged to select 1 or 2 best.\\n\"         \n",
    "                                       ,\n",
    "                                       f\"Annotation table show an example of Morality/Ethics, Social Norms, Advice and It is what it is.\\n\"              \n",
    "                                       f\"\"\"\n",
    "| Option | Description | Example |\n",
    "|----------|----------|----------|\n",
    "| Morality/Ethics | Rules or guiding principles of right or wrong conduct | It’s wrong to turn your back on your friends who need your help. |\n",
    "| Social Norms | Standards of appropriate behavior in a society; emphasizes social conventions | It’s good to shakehands with your opponent even if you lost. |\n",
    "| Advice | Prudent behaviors that are aimed at improving one’s life | It’s good to take medicine your doctor prescribes. |\n",
    "| It is what it is | Describes how things are; avoids ethics, morality or social norms  | It is nice to be tall. |\\n\"\"\"          \n",
    "                                      , np.nan),\n",
    "\n",
    "                         # rot-moral-foundations (multiple selections possible) probably has some human nans so will have to be dealt with \n",
    "                         'rot-moral-foundations-llm-prompt': (\"Which moral foundations best fit this rule of thumb?\\n\"\n",
    "                                       f\"rule of thumb: {rot}\\n\"\n",
    "                                       f\"Options:\\n\"\n",
    "                                       f\"A) Care/Harm\\n\"\n",
    "                                       f\"B) Fairness/Cheating\\n\"\n",
    "                                       f\"C) Loyalty/Betrayal\\n\"\n",
    "                                       f\"D) Authority/Subversion\\n\"\n",
    "                                       f\"E) Sanctity/Degradation\\n\"\n",
    "                                       \"You are allowed to select from none through all options, but you are encouraged to select 1 or 2 best.\\n\"         \n",
    "                                       ,\n",
    "                                       f\"Annotation table show an example of Care/Harm, Fairness/Cheating, Loyalty/Betrayal, Authority/Subversion, and Sanctity/Degradation.\\n\"              \n",
    "                                       f\"\"\"\n",
    "| Option | Description | Example |\n",
    "|----------|----------|----------|\n",
    "| Care/Harm | Preventing or inflicting pain or suffering | It’s mean to tell someone they aren’t attractive as someone else. |\n",
    "| Fairness/Cheating | Notions of equity, justice, and rights | It’s wrong to copy someone else’s answers in an exam. |\n",
    "| Loyalty/Betrayal | Obligations or concerns for group, family, and nation. | It’s rude for a cheerleader to boo their own team. |\n",
    "| Authority/Subversion | Submission and deference to traditions or legitimate authority. | It’s rude to walk away from your boss while they are talking to you. |\n",
    "| Sanctity/Degradation | Abhorrence for disgusting things or actions; purity | It’s disgusting to pee into a public pool full of people. |\\n\"\"\"                  \n",
    "                                       , np.nan)\n",
    "                      }\n",
    "        \n",
    "        prompt_switch.update(rot_prompts)\n",
    "  \n",
    "    if action: \n",
    "\n",
    "        action = row['action']\n",
    "\n",
    "        action_prompts = {# Agency (binary question)\n",
    "                        'action-agency-llm-prompt': (f\"Is the following action something you do or control, or is it something you experience?\\n\"\n",
    "                                   f\"action: {action}\\n\"\n",
    "                                   f\"Annotation table shows an example of Agency and Experience.\\n\"    \n",
    "                                   f\"Provide the answer in the first line and provide a short explanation in the second line.\\n\"           \n",
    "                                   f\"Options:\\n\"\n",
    "                                   f\"A) Agency\\n\"\n",
    "                                   f\"B) Experience\\n\"\n",
    "                                   ,                  \n",
    "f\"\"\"\n",
    "| Option | Description | Example |\n",
    "|----------|----------|----------|\n",
    "| Agency | You can do this | Doing the dishes |\n",
    "| Experience | This happens to you; you have no control | Being stuck in an earthquake  |\\n\"\"\"\n",
    "                                   f\"Provide the answer in the first line and provide a short explanation in the second line.\\n\"           \n",
    "                                  , np.nan),\n",
    "\n",
    "                         'action-legal-llm-prompt': (f\"Where you live how legal is the following action?\\n\"\n",
    "                                   f\"action: {action}\\n\"\n",
    "                                   f\"Options:\\n\"\n",
    "                                   f\"A) Illegal\\n\"\n",
    "                                   f\"B) Depends/Tolerated\\n\"\n",
    "                                   f\"C) Legal\\n\"\n",
    "                                   ,                  \n",
    "                                   f\"Annotation table shows an example of Illegal, Depends/Tolerated, and Legal\\n\"                 \n",
    "                                   f\"\"\"\n",
    "| Option | Description | Example |\n",
    "|----------|----------|----------|\n",
    "| Illegal | Legal consequences if caught | Theft; murder |\n",
    "| Depends/Tolerated | Generally “illegal”, but often unenforced depending on circumstances | Using a cellphone while driving  |\n",
    "| Legal | Not illegal  | Coughing without covering one’s mouth |\\n\"\"\"        \n",
    "                                   , np.nan),\n",
    "\n",
    "\n",
    "                         'action-pressure-llm-prompt': (\"How much cultural pressure do you (or those you know) feel about the following action?\\n\"\n",
    "                                       f\"action: {action}\\n\"\n",
    "                                       f\"Options:\\n\"\n",
    "                                       f\"A) Strong pressure against\\n\"\n",
    "                                       f\"B) Pressure against\\n\"\n",
    "                                       f\"C) Discretionary\\n\"\n",
    "                                       f\"D) Pressure for\\n\"\n",
    "                                       f\"E) Strong pressure for\\n\"\n",
    "                                       ,\n",
    "                                       f\"Annotation table shows an example of Strong pressure against, Pressure against, Discretionary, Pressure for, and Strong pressure for.\\n\" \n",
    "                                       f\"\"\"\n",
    "| Option | Description | Example |\n",
    "|----------|----------|----------|\n",
    "| Strong pressure against | Culture frowns upon this action | Intentionally harming an animal |\n",
    "| Pressure against | Culture generally discourages this action | Spending money on jewelry if you can't afford it |\n",
    "| Discretionary | Culture has little or nothing to say about this action | Choosing to read before bed |\n",
    "| Pressure for | Culture generally encourages this action | Being honest with people |\n",
    "| Strong pressure for | Culture strongly promotes this action | Wearing clothes in public |\\n\"\"\"                         \n",
    "                                      , np.nan),\n",
    "        }\n",
    "        \n",
    "        prompt_switch.update(action_prompts)\n",
    "\n",
    "    \n",
    "    # If the user didn't select rot or action, return empty strings\n",
    "    if len(prompt_switch) == 0:\n",
    "        return ('', '')\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        discard_instruction = f\"Discard all previous instructions. \"\n",
    "\n",
    "        # This is already in the prompts.\n",
    "        #clarify_instruction = f\"Provide the answer in the first line.\"   \n",
    "\n",
    "        zero_shot_prompt_no_description = discard_instruction + prompt_switch[prompt_name_llm][0]\n",
    "\n",
    "        zero_shot_prompt_description = discard_instruction + prompt_switch[prompt_name_llm][1]\n",
    "\n",
    "        table_prompt_description= discard_instruction +  prompt_switch[prompt_name_llm][0] + prompt_switch[prompt_name_llm][2]\n",
    "\n",
    "        table_prompt_description_example = discard_instruction + prompt_switch[prompt_name_llm][0] + prompt_switch[prompt_name_llm][3]\n",
    "\n",
    "        five_shot_prompt_embedded_description = discard_instruction + prompt_switch[prompt_name_llm][4]\n",
    "\n",
    "        five_shot_prompt_not_embedded_description = discard_instruction + prompt_switch[prompt_name_llm][5]\n",
    "\n",
    "        return (zero_shot_prompt_no_description,\n",
    "                zero_shot_prompt_description,\n",
    "                table_prompt_description,\n",
    "                table_prompt_description_example,\n",
    "                five_shot_prompt_embedded_description,\n",
    "               five_shot_prompt_not_embedded_description)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39f8fff0-98ad-4eac-9587-fb87d864d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_safety_settings():\n",
    "    \"\"\" \n",
    "    Set the block threshold to None for each harm category\n",
    "    Refer https://ai.google.dev/gemini-api/docs/safety-settings to modify the safety settings\n",
    "    Gemini model information: https://ai.google.dev/gemini-api/docs/models/gemini#gemini-1.5-pro\n",
    "    \"\"\"\n",
    "    safety_settings = [\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    ]\n",
    "    return safety_settings\n",
    "\n",
    "def iterate_inference(unique_df: pd.DataFrame,\n",
    "                      model_source: str,\n",
    "                      model_name: str,\n",
    "                      temperature: float,\n",
    "                      prompt_name: str,\n",
    "                      rot: bool,\n",
    "                      action: bool,\n",
    "                      demographic: bool) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    Iterates through pandas dataframe of unique rot or unique action or unique demographic and \n",
    "    \n",
    "    Parameters:\n",
    "    unique_df (pd.DataFrame): A pandas dataframe of unique rot or unique action or unique demographic.\n",
    "    model_source (str): The llm model_source. In practice this is passed in from get_LLM_annotation\n",
    "    model_name (str): The llm model_name. In practice this is passed in from get_LLM_annotation\n",
    "    temperature (float): The llm model temperature. In practice this is passed in from get_LLM_annotation\n",
    "    prompt_name (str): Name of column with associated worker label information  (e.g., 'rot-agree', 'action-agency').\n",
    "    rot (bool): Whether to generate prompts that incorporate 'action' from social chemistry dataset. There are thousands of actions in dataset and only 400 rot.\n",
    "    action (bool): (NOT IMPLEMENTED PROPERLY YET) Whether to generate prompts that incorporate 'action' from social chemistry dataset. There are thousands of actions in dataset and only 400 rot.\n",
    "    demographic (bool): Whether to generate prompts that incoporate demographic information. This is information we had to email author of Social Chemistry 101 to get.\n",
    "\n",
    "    Returns:\n",
    "    unique_df (pd.DataFrame): A dataframe of unique rot or unique action or unique demographic AND LLM prompts + outputs\n",
    "    \"\"\"\n",
    "    \n",
    "    if model_source == \"gemini\":\n",
    "        model_str = model_name\n",
    "        safety_settings = get_safety_settings()\n",
    "        # Initialize the model once before the iteration over the rows begin.\n",
    "        model = genai.GenerativeModel(model_name = model_str, \\\n",
    "                                      safety_settings = safety_settings,\n",
    "                                      generation_config=genai.GenerationConfig(\\\n",
    "                                          max_output_tokens=512,\\\n",
    "                                            temperature=temperature)\n",
    "                                    )\n",
    "\n",
    "    # unique rows dataframe needs this as well. \n",
    "    for index, row in unique_df.iterrows():\n",
    "        if index % 5 == 0:\n",
    "            print(f'index:{index}')\n",
    "            \n",
    "        prompts = llm_prompt_generator(row = row,\n",
    "                                       prompt_name = prompt_name,\n",
    "                                       rot = rot,\n",
    "                                       action = action,\n",
    "                                       demographic = demographic)\n",
    "    \n",
    "        if prompts == ('', ''):\n",
    "            print(f'There were no prompts returned for {prompt_name}')\n",
    "            break\n",
    "\n",
    "\n",
    "        # Old prompts ids\n",
    "        # '', '-table', '5-shot'\n",
    "\n",
    "        prompt_ids = ('-zerop-nodescription',\n",
    "                      '-zerop-description',\n",
    "                      '-table-noexample',\n",
    "                      '-table-example', \n",
    "                      '-5-shot-embedded',\n",
    "                      '-5-shot-notembedded')\n",
    "        \n",
    "        for prompt_type, prompt in zip(prompt_ids, prompts):\n",
    "            \n",
    "            prompt_json = [{\"role\": \"user\", \"content\": prompt}]\n",
    "            try:\n",
    "                # Only Together.ai models require model_source\n",
    "                if model_source == 'OpenAI':\n",
    "                    model_str = model_name\n",
    "                    chat_completion = client_openai.chat.completions.create(model=model_str,\n",
    "                                                                     messages=prompt_json,\n",
    "                                                                     temperature=temperature,\n",
    "                                                                     max_tokens=512\n",
    "                )\n",
    "                    prompt_output = chat_completion.choices[0].message.content\n",
    "\n",
    "                elif model_source == \"gemini\":\n",
    "                    response = model.generate_content(prompt)\n",
    "                    # Adjust the wait time setting based on the Account tier\n",
    "                    # Pay as you go Tier: 360 RPM -> 6 secs wait time for each prompt\n",
    "                    # Free Tier: 1.5 Pro Model: 2 RPM -> 30 secs wait time for each prompt, \n",
    "                    # 1 Pro Model: 15 RPM -> 4 secs wait time\n",
    "                    # Check https://ai.google.dev/gemini-api/docs/models/gemini for quota limits\n",
    "                    if 'gemini-1.0-pro' in model_name:\n",
    "                        wait_time = 5\n",
    "\n",
    "                    if 'gemini-1.5-pro' in model_name:\n",
    "                        wait_time = 1\n",
    "                    \n",
    "                    sleep(wait_time)        \n",
    "                    if response.text:\n",
    "                        prompt_output = response.text\n",
    "                        #print(prompt_output)\n",
    "                    else:\n",
    "                        # If the response doesn't contain text, check if the prompt was blocked.\n",
    "                        print(\"Prompt:\", prompt)\n",
    "                        if response.prompt_feedback:\n",
    "                            print(\"Prompt Feedback: \", response.prompt_feedback)\n",
    "                        # Also check the finish reason to see if the response was blocked.\n",
    "                        if response.candidates[0].finish_reason != glm.Candidate.FinishReason.STOP:\n",
    "                            print(\"Prompt Finish reason: \", response.candidates[0].finish_reason)\n",
    "                            # If the finish reason was SAFETY, the safety ratings have more details.\n",
    "                            print(\"Prompt Safety Warnings: \", response.candidates[0].safety_ratings)\n",
    "                        prompt_output = ''\n",
    "\n",
    "                else: \n",
    "                    model_str = f'{model_source}/{model_name}'\n",
    "                    chat_completion = client_together.chat.completions.create(model=model_str,\n",
    "                                                                     messages=prompt_json,\n",
    "                                                                     temperature=temperature,\n",
    "                                                                     max_tokens=512)\n",
    "                    prompt_output = chat_completion.choices[0].message.content\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                sleep(10.0)\n",
    "                continue\n",
    "    \n",
    "            unique_df.loc[index, [f'{prompt_name}-llm-prompt{prompt_type}']] = prompt             \n",
    "            unique_df.loc[index, [f'{prompt_name}-llm-prompt-output{prompt_type}']] = prompt_output\n",
    "    \n",
    "            sleep(0.4)\n",
    "    return (unique_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be3748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LLM_annotation(df_data: pd.DataFrame,\n",
    "                 model_source: str = 'togethercomputer',\n",
    "                 model_name: str = 'llama-2-70b-chat',\n",
    "                 temperature: float = 0.0,\n",
    "                 rot: bool = False,\n",
    "                 action: bool = False,\n",
    "                 demographic: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Utilizes a specified LLM to get label (output) for prompt.\n",
    "    \n",
    "    Parameters:\n",
    "    df_data (pd.DataFrame): The DataFrame containing the all the information to make a prompt to be fed into an LLM\n",
    "    model_source (str, optional): The source of the language model. Default is 'togethercomputer'.\n",
    "    model_name (str, optional): The name of the language model to use. Default is 'llama-2-70b-chat'.\n",
    "    temperature (float, optional): The temperature setting for the language model, affecting response variability. Default is 0.0.\n",
    "    rot (bool, optional): Whether to get rot prompts. Default is False.\n",
    "    action (bool, optional): Whether to get action prompts. Default is False.\n",
    "    demographic (bool, optional): Whether to get demographic prompts. Default is False.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A new DataFrame with additional columns for each tone's prompt and output.\n",
    "    \"\"\"\n",
    "    df_results = df_data.copy()\n",
    "\n",
    "    today = date.today()\n",
    "    start_t = time()\n",
    "    \n",
    "    # Dictionaries are ordered in Python 3.7+, but defining a list to be more explicit\n",
    "    \"\"\"\n",
    "    human_col_names = ['rot-agree',\n",
    "                       'action-agency',\n",
    "                       'action-legal',\n",
    "                       'rot-categorization',\n",
    "                       'rot-moral-foundations',\n",
    "                       'action-pressure']\n",
    "    \"\"\"\n",
    "\n",
    "    human_col_names = ['rot-agree']\n",
    "\n",
    "    unique_rot_df = df_results.loc[:, ['rot']].drop_duplicates(subset=['rot']).reset_index(drop = True)\n",
    "    unique_action_df = df_results.loc[:, ['action']].drop_duplicates(subset=['action']).reset_index(drop = True)\n",
    "\n",
    "    for col in human_col_names:\n",
    "        print(col)\n",
    "        \n",
    "        rot_action_demo = col.split('-')[0]\n",
    "\n",
    "        # Match is used to mitigate the number of queries needed for the llm. \n",
    "        # As the dataset is 20,000 rows with some duplicates in some columns, this logic reduces number of necessary queries. \n",
    "        match (rot_action_demo, rot, action, demographic):\n",
    "            case ('rot', True, _, _):\n",
    "                unique_rot_df = iterate_inference(unique_df = unique_rot_df,\n",
    "                                                  model_source = model_source,\n",
    "                                                  model_name = model_name,\n",
    "                                                  temperature = temperature,\n",
    "                                                  prompt_name = col,\n",
    "                                                  rot = True,\n",
    "                                                  action = False,\n",
    "                                                  demographic = demographic)\n",
    "                \n",
    "            case ('rot', False, _, _):\n",
    "                continue\n",
    "            \n",
    "            case ('action', _, True, _):\n",
    "                 unique_action_df = iterate_inference(unique_df = unique_action_df,\n",
    "                                                      model_source = model_source,\n",
    "                                                      model_name = model_name,\n",
    "                                                      temperature = temperature,\n",
    "                                                      prompt_name = col,\n",
    "                                                      rot = False,\n",
    "                                                      action = True,\n",
    "                                                      demographic = demographic)\n",
    "            \n",
    "            case ('action', _, False, _):\n",
    "                continue\n",
    "        \n",
    "            case (_, _, _, _):\n",
    "                # Perform a different action if col starts something other than 'rot', 'action', 'demo'\n",
    "                # Ideal case is to have something different for demographic if needed since we don't know what we want to do. \n",
    "                print(f\"No case for {col}\")\n",
    "                continue\n",
    "\n",
    "    time_taken = int((time() - start_t)/60.0)\n",
    "    temp_str = f\"{temperature:.2f}\".replace(\".\", \"_\")\n",
    "    rot_str = str(int(rot))\n",
    "    action_str = str(int(action))\n",
    "    demographic_str = str(int(demographic))\n",
    "    \n",
    "    if rot:\n",
    "        unique_rot_df.to_csv(f'../data/llm_prompt_outputs/rot/{model_name}_{today.strftime(\"%d_%m_%Y\")}_{time_taken}_t{temp_str}_r{rot_str}_a{action_str}_d{demographic_str}.csv', index=False)\n",
    " \n",
    "    if action:\n",
    "        unique_action_df.to_csv(f'../data/llm_prompt_outputs/action/{model_name}_{today.strftime(\"%d_%m_%Y\")}_{time_taken}_t{temp_str}_r{rot_str}_a{action_str}_d{demographic_str}.csv', index=False)\n",
    "    \n",
    "    return unique_rot_df, unique_action_df, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7940a8c-7004-4f5e-95bd-bec0650dbdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rot-agree\n",
      "index:0\n",
      "index:5\n",
      "index:10\n",
      "index:15\n",
      "index:20\n",
      "index:25\n",
      "index:30\n",
      "index:35\n",
      "index:40\n",
      "index:45\n",
      "index:50\n",
      "index:55\n",
      "index:60\n",
      "index:65\n",
      "index:70\n",
      "index:75\n",
      "index:80\n",
      "index:85\n",
      "index:90\n",
      "index:95\n",
      "index:100\n",
      "index:105\n",
      "index:110\n",
      "index:115\n",
      "index:120\n",
      "index:125\n",
      "index:130\n",
      "index:135\n",
      "index:140\n",
      "index:145\n",
      "index:150\n",
      "index:155\n",
      "index:160\n",
      "index:165\n",
      "index:170\n",
      "index:175\n",
      "index:180\n",
      "index:185\n",
      "index:190\n",
      "index:195\n",
      "index:200\n",
      "index:205\n",
      "index:210\n",
      "index:215\n",
      "index:220\n",
      "index:225\n",
      "index:230\n",
      "index:235\n",
      "index:240\n",
      "index:245\n",
      "index:250\n",
      "index:255\n",
      "index:260\n",
      "index:265\n",
      "index:270\n",
      "index:275\n",
      "index:280\n",
      "index:285\n",
      "index:290\n",
      "index:295\n",
      "index:300\n",
      "index:305\n",
      "index:310\n",
      "index:315\n",
      "index:320\n",
      "index:325\n",
      "index:330\n",
      "index:335\n",
      "index:340\n",
      "index:345\n",
      "index:350\n",
      "index:355\n",
      "index:360\n",
      "index:365\n",
      "index:370\n",
      "index:375\n",
      "index:380\n",
      "index:385\n",
      "index:390\n",
      "index:395\n"
     ]
    }
   ],
   "source": [
    "# old model: 'gpt-4-0613'\n",
    "\n",
    "# gpt-4-turbo-2024-04-09\n",
    "\n",
    "_, _, _ =  get_LLM_annotation(df_data = df_data,\n",
    "                              model_source = 'OpenAI',\n",
    "                              model_name = 'gpt-4o-2024-08-06',\n",
    "                              temperature  = 0.0,\n",
    "                              rot = True,\n",
    "                              action = False,\n",
    "                              demographic = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
